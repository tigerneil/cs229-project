{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'data/'\n",
    "fj_unlabeled_font_vectors = pd.read_pickle(dir_path + 'fj_ul_font_vectors.pkl')\n",
    "fj_labeled_font_vectors = pd.read_pickle(dir_path + 'fj_l_font_vectors.pkl')\n",
    "common_attribute_labels = pd.read_pickle(dir_path + 'common_attribute_labels.pkl')\n",
    "\n",
    "attribute_names = np.loadtxt(dir_path + 'attrNames.txt', dtype=str)\n",
    "typographic_features = np.asarray(['font_name', 'capitals', 'cursive', 'display', 'italic', 'monospace', 'serif'])\n",
    "semantic_features = attribute_names[~np.isin(attribute_names, typographic_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fj_labeled_font_vectors.iloc[:, 1:]\n",
    "y = common_attribute_labels.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_attr_table = pd.DataFrame(data=[], index=semantic_features)\n",
    "error_table = pd.DataFrame(data=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error by attribute (ordered by error, ascending):\n",
      "                        0\n",
      "gentle              0.060\n",
      "fresh               0.065\n",
      "charming            0.067\n",
      "delicate            0.069\n",
      "wide                0.071\n",
      "calm                0.078\n",
      "friendly            0.079\n",
      "soft                0.082\n",
      "attention-grabbing  0.083\n",
      "strong              0.090\n",
      "sloppy              0.092\n",
      "graceful            0.093\n",
      "happy               0.094\n",
      "pretentious         0.096\n",
      "boring              0.097\n",
      "thin                0.097\n",
      "attractive          0.099\n",
      "modern              0.108\n",
      "warm                0.111\n",
      "clumsy              0.111\n",
      "bad                 0.115\n",
      "sharp               0.116\n",
      "artistic            0.117\n",
      "disorderly          0.117\n",
      "playful             0.117\n",
      "legible             0.119\n",
      "technical           0.120\n",
      "dramatic            0.120\n",
      "angular             0.121\n",
      "formal              0.128\n",
      "complex             0.129\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "random_seeds = np.array(X.drop(index=i).iloc[np.random.choice(X.drop(index=i).shape[0], 20, replace=False)])\n",
    "\n",
    "model = MeanShift(bandwidth=150)#, seeds=random_seeds)\n",
    "for i, row in X.iterrows():\n",
    "    model.fit(X.drop(index=i))\n",
    "#     print(model.cluster_centers_.shape)\n",
    "    closest_centroid = model.predict(X.iloc[i, :].values.reshape(1, -1))\n",
    "#     print(closest_centroid)\n",
    "#     print(model.predict(X))\n",
    "    neighbor_points_indices = model.predict(X) == closest_centroid\n",
    "    neighbor_points_indices[i] = False  # exclude the true answer itself\n",
    "    f_p = np.array(y[neighbor_points_indices]).mean(axis=0)  # uncomment for unweighted mean\n",
    "#     distances_to_neighbors = np.sqrt(((np.array(X[neighbor_points_indices]) - np.array(X.iloc[i, :]))**2).sum(axis=1))\n",
    "#     distances_to_neighbors = 1 / distances_to_neighbors\n",
    "#     distances_to_neighbors /= distances_to_neighbors.max()\n",
    "#     f_p = np.average(np.array(y[neighbor_points_indices]), weights=distances_to_neighbors, axis=0)\n",
    "    f_t = y.iloc[i, :].values\n",
    "    e = np.abs(f_t - f_p)\n",
    "    errors.append(e)\n",
    "errors = np.asarray(errors)\n",
    "avg_errors = np.mean(errors, axis=0)\n",
    "result = pd.DataFrame(data=avg_errors, index=attribute_names)\n",
    "semantic_result = result[result.index.isin(semantic_features)]\n",
    "\n",
    "print('Error by attribute (ordered by error, ascending):')\n",
    "print(semantic_result.sort_values(by=0).round(3))\n",
    "\n",
    "semantic_result.columns = ['Unweighted Mean Shift 150']\n",
    "error_by_attr_table = pd.concat([error_by_attr_table, semantic_result, ], axis=1)\n",
    "error_table = pd.concat([error_table, semantic_result.mean().round(3), ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0\n",
      "Weighted Mean Shift 150    0.099\n",
      "Unweighted Mean Shift 150  0.099\n"
     ]
    }
   ],
   "source": [
    "print(error_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
